\documentclass[a4paper]{llncs}

\usepackage[lutzsyntax]{virginialake}\aftrianglefalse
\usepackage[urw-garamond]{mathdesign}
\usepackage{hyperref}

\begin{document}

\title{Normalisation Control in Deep Inference\\ via Atomic Flows II}

\author{Alessio Guglielmi\inst{1,2} and Tom Gundersen\inst{1}}
\institute{University of Bath, Bath BA2 7AY, UK \and INRIA, Nancy-Grand Est, France}

\thanks{Guglielmi is supported by EPSRC grant EP/E042805/1 \emph{Complexity and Non-determinism in Deep Inference} and by an ANR \emph{Senior Chaire d'Excellence} titled \emph{Identity and Geometric Essence of Proofs}. Gundersen is supported by an \emph{Overseas Research Scholarship} and a \emph{Research Studentship} both of the University of Bath.}

\maketitle


We are interested in the normalisation of deep-inference derivations in propositional classical logic. Cuts are admissible from proofs and, dually, axioms are admissible from contradictions. However, neither are admissible from derivations. We therefore work with \emph{streamlining}, introduced in \cite{GuglGund:07:Normalis:lr}, a new, symmetric, notion of normalisation, which generalises both cut and axiom elimination.

At the core of our work lie \emph{atomic flows}, which were introduced in \cite{GuglGund:07:Normalis:lr}. Atomic flows are graphs, similar to Buss flow graphs \cite{Buss:91:The-Unde:uq} and proof nets \cite{Gira:87:Linear-L:wm}, obtained from derivations by tracing their atom occurrences and forgetting everything except how atoms are created, copied, contracted and destroyed. Atomic flows are largely syntax independent and bureaucracy free (in the sense of Girard \cite{Gira:89:Geometry:sh}). We showed how atomic flows are useful in defining new normal forms for derivations and in arguing about normalisation.

In particular, streamlining was defined based on atomic flows. Intuitively, a derivation is streamlined if every path in the associated atomic flow can be extended to reach the top or the bottom of the flow. Seen from the point of view of derivations it means that if you pick an atom occurrence from a streamlined derivation you can trace it up to the premiss or down to the conclusion. Since a proof has no atoms in its premiss (only the unit `true'), tracing atom occurrences upwards from a cut can not lead to the premiss. Hence, a streamlined proof is cut free.

In this paper, we present a new streamlining procedure. Similarly to our previous result the procedure is based on a particular way of gluing together pieces of derivation, which is possible due to the symmetries of deep inference. However, the novelties are that no transformation of the original derivation is needed before the pieces are glued together, and much less information about the atomic flow associated with the derivation is used to guide the procedure. In particular, we only need to know which axioms are connected with which cuts. Since we use less information, all the axioms and cuts we are eliminating are indistinguishable, so, unlike the previous procedures, no strategy for streamlining is necessary.

Contrary to what one might expect from cut elimination, the complexity of the procedure is not determined by the number of cuts being eliminated. The complexity is $O(2^n)$, where $n$ is the number of atoms which occur in at least one of the cuts we eliminate. In particular, every step of the procedure eliminate all the cuts where a given atom occurs, making termination a triviality.

Also somewhat surprising is the fact that if we consider the original derivation as a `black box', then the streamlined derivation only depends on the number of atoms being eliminated, not on the contents of the `black box'. We can therefore present our normalisation procedure as building a `skeleton', for a given number of atoms, in which we can plug derivations in order to streamline them.

\newcommand{\SKS}{\mathsf{SKS}}
The results in this paper are presented in the deep-inference formalism the calculus of structures \cite{Gugl:06:A-System:kl}, in particular system $\SKS$ \cite{BrunTiu:01:A-Local-:mz,Brun:04:Deep-Inf:rq}, but we strive at generality and it should not be difficult to adapt our results to any deep-inference formalism and any propositional system as long as we have atomic structural rules and linear logical rules (something we always expect in deep inference and something which is not achievable elsewhere).

In the future, we believe it will be possible to improve on these results by extending them to modal \cite{Brun:07:Deep-Seq:fk,HeinStew:05:Purity-T:tg,StewStou:05:A-System:tg,Stou:06:A-Deep-I:rt} and first order \cite{Brun:04:Deep-Inf:rq,Brun:06:Cut-Elim:cq} logics and by making the procedure quasipolynomial, along the lines of a quasipolynomial cut-elimination procedure we are working on.

For the full version of this paper please refer to \url{http://cs.bath.ac.uk/ag/p/NormContrDIAtFl2.pdf}
%===============================================================================


\bibliographystyle{alpha}
\bibliography{biblio}

\end{document}